{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting+product+price+using+tensorflow+with+NLP.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "jaEpPR7kYPA7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "This model is surprisingly good for this particular dataset, both on it's own,\n",
        "but especially in the ensemble: it has huge variance and each single model is\n",
        "tuned to overfit to a different local minima, but when averaged, they give a really good result.\n",
        "It seems to capture feature interactions which look really important here,\n",
        "and it's fast to train. In order to make it efficient,\n",
        "it's important to use one core for each model and train them in parallel,\n",
        "it's much faster than using all cores for one model, especially for models working on sparse data.\n",
        "It's a bit tricky to make it work with threading,\n",
        "the key here is undocumented use_per_session_threads=1 argument for tf config.\n",
        "Threading makes code simpler and less memory-hungry, but for mxnet we had to use multiprocessing.\n",
        "Another important bit is doubling of the batch size after each epoch: this makes the model faster,\n",
        "and also allows it to overfit more. Also, the bigger is the first hidden layer size, the better.\n",
        "Apart from that, we had a few other tricks with the model but I tried to keep it short in the kernel.\n",
        "\n",
        "The dataset:it's really good to merge several features (category, description, etc.) into one field,\n",
        "so here for simplicity I do just that. In our submission we have many more interesting ideas and features\n",
        "that improve the score further.\n",
        "Another cool idea was to make ensemble more diverse by creating a binary version of each dataset:\n",
        "it means after we get a sparse matrix, we clip all non-zero values to 1.\n",
        "This is almost the same as using a CountVectorizer with binary=True, but massively faster,\n",
        "because we don't need to re-process the data.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "metadata": {
        "id": "vdKSHFPIYPA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6aa940e-3ad4-42cb-a34b-091fa258c23c"
      },
      "cell_type": "code",
      "source": [
        "import os; os.environ['OMP_NUM_THREADS'] = '1'\n",
        "from contextlib import contextmanager\n",
        "from functools import partial\n",
        "from operator import itemgetter\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import time\n",
        "from typing import List, Dict\n",
        "\n",
        "import keras as ks\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as Tfidf\n",
        "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ul6yKMpkYdSv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oOgRekorYPBB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    print(f'[{name}] done in {time.time() - t0:.0f} s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kz74tj4kYPBF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df['name'] = df['name'].fillna('') + ' ' + df['brand_name'].fillna('')\n",
        "    df['text'] = (df['item_description'].fillna('') + ' ' + df['name'] + ' ' + df['category_name'].fillna(''))\n",
        "    return df[['name', 'text', 'shipping', 'item_condition_id']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RTrBFuYWYPBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def on_field(f: str, *vec) -> Pipeline:\n",
        "    return make_pipeline(FunctionTransformer(itemgetter(f), validate=False), *vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVQzMqP4YPBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_records(df: pd.DataFrame) -> List[Dict]:\n",
        "    return df.to_dict(orient='records')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VdqHTyCQYPBP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fit_predict(xs, y_train) -> np.ndarray:\n",
        "    X_train, X_test = xs\n",
        "    config = tf.ConfigProto(\n",
        "        intra_op_parallelism_threads=1, use_per_session_threads=1, inter_op_parallelism_threads=1)\n",
        "    with tf.Session(graph=tf.Graph(), config=config) as sess, timer('fit_predict'):\n",
        "        ks.backend.set_session(sess)\n",
        "        model_in = ks.Input(shape=(X_train.shape[1],), dtype='float32', sparse=True)\n",
        "        out = ks.layers.Dense(192, activation='relu')(model_in)\n",
        "        out = ks.layers.Dense(64, activation='relu')(out)\n",
        "        out = ks.layers.Dense(64, activation='relu')(out)\n",
        "        out = ks.layers.Dense(1)(out)\n",
        "        model = ks.Model(model_in, out)\n",
        "        model.compile(loss='mean_squared_error', optimizer=ks.optimizers.Adam(lr=3e-3))\n",
        "        for i in range(3):\n",
        "            with timer(f'epoch {i + 1}'):\n",
        "                model.fit(x=X_train, y=y_train, batch_size=2**(11 + i), epochs=1, verbose=0)\n",
        "        return model.predict(X_test)[:, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5JKiarFYPBR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ee1ff7ba-89a7-4188-96cf-34d6d3f0f143"
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    vectorizer = make_union(\n",
        "        on_field('name', Tfidf(max_features=100000, token_pattern='\\w+')),\n",
        "        on_field('text', Tfidf(max_features=100000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
        "        on_field(['shipping', 'item_condition_id'],\n",
        "                 FunctionTransformer(to_records, validate=False), DictVectorizer()),\n",
        "        n_jobs=4)\n",
        "    y_scaler = StandardScaler()\n",
        "    with timer('process train'):\n",
        "        train = pd.read_table('train.tsv')\n",
        "        train = train[train['price'] > 0].reset_index(drop=True)\n",
        "        cv = KFold(n_splits=20, shuffle=True, random_state=42)\n",
        "        train_ids, valid_ids = next(cv.split(train))\n",
        "        train, valid = train.iloc[train_ids], train.iloc[valid_ids]\n",
        "        y_train = y_scaler.fit_transform(np.log1p(train['price'].values.reshape(-1, 1)))\n",
        "        X_train = vectorizer.fit_transform(preprocess(train)).astype(np.float32)\n",
        "        print(f'X_train: {X_train.shape} of {X_train.dtype}')\n",
        "        del train\n",
        "    with timer('process valid'):\n",
        "        X_valid = vectorizer.transform(preprocess(valid)).astype(np.float32)\n",
        "    with ThreadPool(processes=4) as pool:\n",
        "        Xb_train, Xb_valid = [x.astype(np.bool).astype(np.float32) for x in [X_train, X_valid]]\n",
        "        xs = [[Xb_train, Xb_valid], [X_train, X_valid]] * 2\n",
        "        y_pred = np.mean(pool.map(partial(fit_predict, y_train=y_train), xs), axis=0)\n",
        "    y_pred = np.expm1(y_scaler.inverse_transform(y_pred.reshape(-1, 1))[:, 0])\n",
        "    print('Valid RMSLE: {:.4f}'.format(np.sqrt(mean_squared_log_error(valid['price'], y_pred))))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (1407577, 200002) of float32\n",
            "[process train] done in 259 s\n",
            "[process valid] done in 44 s\n",
            "[epoch 1] done in 1530 s\n",
            "[epoch 1] done in 1534 s\n",
            "[epoch 1] done in 1536 s\n",
            "[epoch 1] done in 1540 s\n",
            "[epoch 2] done in 825 s\n",
            "[epoch 2] done in 825 s\n",
            "[epoch 2] done in 830 s\n",
            "[epoch 2] done in 825 s\n",
            "[epoch 3] done in 474 s\n",
            "[epoch 3] done in 482 s\n",
            "[epoch 3] done in 474 s\n",
            "[epoch 3] done in 476 s\n",
            "[fit_predict] done in 2857 s\n",
            "[fit_predict] done in 2859 s\n",
            "[fit_predict] done in 2860 s\n",
            "[fit_predict] done in 2860 s\n",
            "Valid RMSLE: 0.3872\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}